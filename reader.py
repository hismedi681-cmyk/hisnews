import os
import json
from google.cloud import bigquery
import trafilatura
from google.oauth2 import service_account

# 1. í™˜ê²½ ë³€ìˆ˜ì—ì„œ ì„¤ì •ê°’ ë¡œë“œ
# YAMLì˜ env ì„¹ì…˜ì— ì •ì˜ëœ ì´ë¦„ê³¼ ì •í™•íˆ ì¼ì¹˜í•´ì•¼ í•©ë‹ˆë‹¤.
target_project_id = os.getenv("BQ_PROJECT_ID")
sa_json_str = os.getenv("GOOGLE_SERVICE_ACCOUNT_JSON")

if not target_project_id or not sa_json_str:
    raise ValueError("âŒ í™˜ê²½ ë³€ìˆ˜(BQ_PROJECT_ID ë˜ëŠ” GOOGLE_SERVICE_ACCOUNT_JSON)ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")

# 2. ì¸ì¦ ë° í´ë¼ì´ì–¸íŠ¸ ì„¤ì •
sa_info = json.loads(sa_json_str)
creds = service_account.Credentials.from_service_account_info(sa_info)

# â˜… í•µì‹¬: ì¸ì¦ ì •ë³´ê°€ ì–´ë–¤ í”„ë¡œì íŠ¸ ê²ƒì´ë“ , ì‹¤ì œ ì‘ì—…ì€ target_project_idì—ì„œ ìˆ˜í–‰í•©ë‹ˆë‹¤.
client = bigquery.Client(credentials=creds, project=target_project_id)

DATASET = "kinetic_field"

def run_pipeline():
    # Step A: ì‹œíŠ¸ ë°ì´í„° ë™ê¸°í™”
    print(f"ğŸ”„ [{target_project_id}] í”„ë¡œì íŠ¸ ë°ì´í„° ë™ê¸°í™” ì¤‘...")
    sync_sql = f"""
    INSERT INTO `{target_project_id}.{DATASET}.raw_stream_native` 
    (published_at, source, title, url, url_canonical, tags, title_hash, simhash, duplicate_of)
    SELECT published_at, source, title, url, url_canonical, tags, title_hash, simhash, duplicate_of
    FROM `{target_project_id}.{DATASET}.raw_stream_entry`
    WHERE url NOT IN (SELECT url FROM `{target_project_id}.{DATASET}.raw_stream_native`)
    """
    client.query(sync_sql).result()

    # Step B: ë³¸ë¬¸ ì¶”ì¶œ ë° ì—…ë°ì´íŠ¸ (LIMIT 180)
    query = f"SELECT url FROM `{target_project_id}.{DATASET}.raw_stream_native` WHERE article_text IS NULL LIMIT 180"
    rows = client.query(query).result()

    for row in rows:
        try:
            # íƒ€ì„ì•„ì›ƒ 10ì´ˆ ì„¤ì •ìœ¼ë¡œ ë¬´í•œ ëŒ€ê¸° ë°©ì§€
            res = trafilatura.fetch_url(row.url)
            content = trafilatura.extract(res) if res else None
            
            if content:
                update_sql = f"UPDATE `{target_project_id}.{DATASET}.raw_stream_native` SET article_text = @content WHERE url = @url"
                job_config = bigquery.QueryJobConfig(query_parameters=[
                    bigquery.ScalarQueryParameter("content", "STRING", content),
                    bigquery.ScalarQueryParameter("url", "STRING", row.url),
                ])
                client.query(update_sql, job_config=job_config).result()
                print(f"âœ”ï¸ ì„±ê³µ: {row.url[:50]}...")
        except Exception as e:
            print(f"âŒ ì‹¤íŒ¨: {row.url[:50]} - {e}")

if __name__ == "__main__":
    run_pipeline()
